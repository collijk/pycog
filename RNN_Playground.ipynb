{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import os\n",
    "import sys\n",
    "from os.path import join\n",
    "from pycog.utils import mkdir_p\n",
    "import numpy as np\n",
    "\n",
    "name = 'rdm_dense'\n",
    "\n",
    "base = os.path.abspath(os.getcwd())\n",
    "examplespath = join(base, 'examples')\n",
    "modelspath = join(examplespath, 'models')\n",
    "analysispath = join(examplespath, 'analysis')\n",
    "workpath = join(base, name)\n",
    "datapath = join(workpath, 'data')\n",
    "figspath = join(workpath, 'figs')\n",
    "trialspath = join(workpath, 'trials')\n",
    "\n",
    "for path in [datapath, figspath, trialspath]:\n",
    "    mkdir_p(path)\n",
    "\n",
    "\n",
    "# Select which model file to use here.\n",
    "modelfile = join(modelspath, name + '.py')\n",
    "# Select the corresponding analysis script here.\n",
    "runfile = join(analysispath, 'rdm.py')\n",
    "\n",
    "# Set the data file name here\n",
    "savefile = join(datapath, name + '.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> settings\n",
      "   | GPU:                       no\n",
      "   | init seed:                 1001\n",
      "   | distribution (Win):        uniform\n",
      "   | distribution (Wrec):       gamma\n",
      "   | distribution (Wout):       uniform\n",
      "   | Nin/N/Nout:                2/100/2\n",
      "   | Dale's law:                E/I = 80/20\n",
      "   | initial spectral radius:   1.50\n",
      "   | train recurrent bias:      no\n",
      "   | train output bias:         no\n",
      "   | train initial conditions:  yes\n",
      "   | sparseness (Wrec):         p = 0.99, p_plastic = 0.99\n",
      "   | sparseness (Wout):         p = 0.80, p_plastic = 0.80\n",
      "   | E/I positivity function:   rectify\n",
      "   | hidden activation:         rectify\n",
      "   | output activation/loss:    linear/squared\n",
      "   | mode:                      batch\n",
      "   | output mask:               yes\n",
      "   | sigma_in:                  0.01\n",
      "   | sigma_rec:                 0.15\n",
      "   | rectify inputs:            True\n",
      "   | gradient minibatch size:   20\n",
      "   | validation minibatch size: 1100\n",
      "   | dt:                        20.0 ms\n",
      "   | tau:                       100 ms\n",
      "   | tau_in:                    100 ms\n",
      "   | learning rate:             0.01\n",
      "   | lambda_Omega:              2\n",
      "   | max gradient norm:         1\n",
      "   | (Theano) floatX:           float32\n",
      "   | (Theano) allow_gc:         False\n",
      "0 updates - Dec 5 2016 2:49:56 AM (0 hrs 0 mins 0 secs elapsed)\n",
      "| validation loss / RMSE / performance: 1.200041 / 1.095464 / 50.50 --- NEW BEST (prev. best: inf)\n",
      "| Omega      (last iter) = n/a\n",
      "| grad. norm (last iter) = n/a\n",
      "| rho                    = 1.50000000\n",
      "500 updates - Dec 5 2016 2:50:14 AM (0 hrs 0 mins 17 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.116645 / 0.341534 / 51.90 --- NEW BEST (prev. best: 1.200041)\n",
      "| Omega      (last iter) = 0.05052355\n",
      "| grad. norm (last iter) = 0.32027924\n",
      "| rho                    = 1.78744566\n",
      "1000 updates - Dec 5 2016 2:50:31 AM (0 hrs 0 mins 34 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.091588 / 0.302636 / 51.00 --- NEW BEST (prev. best: 0.116645)\n",
      "| Omega      (last iter) = 0.02065585\n",
      "| grad. norm (last iter) = 0.33288461\n",
      "| rho                    = 1.87009549\n",
      "1500 updates - Dec 5 2016 2:50:49 AM (0 hrs 0 mins 52 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.088620 / 0.297692 / 50.70 --- NEW BEST (prev. best: 0.091588)\n",
      "| Omega      (last iter) = 0.02354797\n",
      "| grad. norm (last iter) = 0.21652791\n",
      "| rho                    = 1.87660491\n",
      "2000 updates - Dec 5 2016 2:51:06 AM (0 hrs 1 mins 10 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.087457 / 0.295731 / 51.10 --- NEW BEST (prev. best: 0.088620)\n",
      "| Omega      (last iter) = 0.01415563\n",
      "| grad. norm (last iter) = 0.13721558\n",
      "| rho                    = 1.88651192\n",
      "2500 updates - Dec 5 2016 2:51:24 AM (0 hrs 1 mins 27 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.085127 / 0.291766 / 55.00 --- NEW BEST (prev. best: 0.087457)\n",
      "| Omega      (last iter) = 0.01125202\n",
      "| grad. norm (last iter) = 0.19115435\n",
      "| rho                    = 1.89465094\n",
      "3000 updates - Dec 5 2016 2:51:41 AM (0 hrs 1 mins 44 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.082056 / 0.286454 / 61.80 --- NEW BEST (prev. best: 0.085127)\n",
      "| Omega      (last iter) = 0.00970031\n",
      "| grad. norm (last iter) = 0.44452131\n",
      "| rho                    = 1.91068792\n",
      "3500 updates - Dec 5 2016 2:51:57 AM (0 hrs 2 mins 1 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.076078 / 0.275822 / 65.50 --- NEW BEST (prev. best: 0.082056)\n",
      "| Omega      (last iter) = 0.00747290\n",
      "| grad. norm (last iter) = 0.96198696\n",
      "| rho                    = 1.93171716\n",
      "4000 updates - Dec 5 2016 2:52:15 AM (0 hrs 2 mins 18 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.067218 / 0.259265 / 71.40 --- NEW BEST (prev. best: 0.076078)\n",
      "| Omega      (last iter) = 0.00492973\n",
      "| grad. norm (last iter) = 2.26500440\n",
      "| rho                    = 1.96674800\n",
      "4500 updates - Dec 5 2016 2:52:31 AM (0 hrs 2 mins 35 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.069238 / 0.263132 / 67.70\n",
      "| Omega      (last iter) = 0.00578256\n",
      "| grad. norm (last iter) = 1.43498755\n",
      "| rho                    = 2.01005864\n",
      "5000 updates - Dec 5 2016 2:52:48 AM (0 hrs 2 mins 52 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.059508 / 0.243943 / 76.10 --- NEW BEST (prev. best: 0.067218)\n",
      "| Omega      (last iter) = 0.01300760\n",
      "| grad. norm (last iter) = 0.44998083\n",
      "| rho                    = 2.04675698\n",
      "5500 updates - Dec 5 2016 2:53:05 AM (0 hrs 3 mins 9 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.059852 / 0.244646 / 75.00\n",
      "| Omega      (last iter) = 0.00671821\n",
      "| grad. norm (last iter) = 0.19919345\n",
      "| rho                    = 2.07683706\n",
      "6000 updates - Dec 5 2016 2:53:23 AM (0 hrs 3 mins 26 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.052801 / 0.229784 / 78.90 --- NEW BEST (prev. best: 0.059508)\n",
      "| Omega      (last iter) = 0.00669900\n",
      "| grad. norm (last iter) = 0.36352849\n",
      "| rho                    = 2.09944844\n",
      "6500 updates - Dec 5 2016 2:53:40 AM (0 hrs 3 mins 44 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.048565 / 0.220375 / 80.90 --- NEW BEST (prev. best: 0.052801)\n",
      "| Omega      (last iter) = 0.00517157\n",
      "| grad. norm (last iter) = 0.47277391\n",
      "| rho                    = 2.12183833\n",
      "7000 updates - Dec 5 2016 2:53:57 AM (0 hrs 4 mins 1 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.045937 / 0.214330 / 82.50 --- NEW BEST (prev. best: 0.048565)\n",
      "| Omega      (last iter) = 0.00719199\n",
      "| grad. norm (last iter) = 0.22534066\n",
      "| rho                    = 2.14296508\n",
      "7500 updates - Dec 5 2016 2:54:14 AM (0 hrs 4 mins 18 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.046044 / 0.214579 / 82.60\n",
      "| Omega      (last iter) = 0.01632726\n",
      "| grad. norm (last iter) = 0.46735185\n",
      "| rho                    = 2.16398787\n",
      "8000 updates - Dec 5 2016 2:54:31 AM (0 hrs 4 mins 35 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.043136 / 0.207691 / 83.20 --- NEW BEST (prev. best: 0.045937)\n",
      "| Omega      (last iter) = 0.00671598\n",
      "| grad. norm (last iter) = 1.57916355\n",
      "| rho                    = 2.17629457\n",
      "8500 updates - Dec 5 2016 2:54:48 AM (0 hrs 4 mins 52 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.041168 / 0.202898 / 84.80 --- NEW BEST (prev. best: 0.043136)\n",
      "| Omega      (last iter) = 0.00738590\n",
      "| grad. norm (last iter) = 0.79522556\n",
      "| rho                    = 2.19590330\n",
      "9000 updates - Dec 5 2016 2:55:05 AM (0 hrs 5 mins 8 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.039680 / 0.199199 / 85.10 --- NEW BEST (prev. best: 0.041168)\n",
      "| Omega      (last iter) = 0.00532914\n",
      "| grad. norm (last iter) = 0.77772230\n",
      "| rho                    = 2.20540810\n",
      "9500 updates - Dec 5 2016 2:55:22 AM (0 hrs 5 mins 25 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.042809 / 0.206903 / 82.20\n",
      "| Omega      (last iter) = 0.00401951\n",
      "| grad. norm (last iter) = 0.21231966\n",
      "| rho                    = 2.21893072\n",
      "10000 updates - Dec 5 2016 2:55:40 AM (0 hrs 5 mins 43 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.038115 / 0.195231 / 85.40 --- NEW BEST (prev. best: 0.039680)\n",
      "| Omega      (last iter) = 0.00511554\n",
      "| grad. norm (last iter) = 0.30883154\n",
      "| rho                    = 2.23587561\n",
      "10500 updates - Dec 5 2016 2:55:57 AM (0 hrs 6 mins 0 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.037885 / 0.194640 / 86.10 --- NEW BEST (prev. best: 0.038115)\n",
      "| Omega      (last iter) = 0.00498227\n",
      "| grad. norm (last iter) = 0.39135486\n",
      "| rho                    = 2.24463916\n",
      "11000 updates - Dec 5 2016 2:56:14 AM (0 hrs 6 mins 18 secs elapsed)\n",
      "| validation loss / RMSE / performance: 0.037514 / 0.193686 / 86.30 --- NEW BEST (prev. best: 0.037885)\n",
      "| Omega      (last iter) = 0.00840613\n",
      "| grad. norm (last iter) = 2.44922829\n",
      "| rho                    = 2.25614095\n",
      "Termination criterion satisfied -- we'll call it a day.\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Training #\n",
    "############\n",
    "\n",
    "from pycog import Model\n",
    "seed = 1001\n",
    "model = Model(modelfile=modelfile)\n",
    "model.train(savefile, seed=seed, recover=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# Run the RNN #\n",
    "###############\n",
    "\n",
    "r = imp.load_source('analysis', runfile)\n",
    "m = imp.load_source('model', modelfile)\n",
    "\n",
    "dt = 0.5 # Default value\n",
    "dt_save = 20 # From all.py\n",
    "\n",
    "action = 'trials'\n",
    "num_trials = 50\n",
    "args = [num_trials]\n",
    "antagonist_level = 0\n",
    "\n",
    "params = {\n",
    "        'seed':       seed,\n",
    "        'model':      m,\n",
    "        'savefile':   savefile,\n",
    "        'name':       name,\n",
    "        'datapath':   datapath,\n",
    "        'figspath':   figspath,\n",
    "        'trialspath': trialspath,\n",
    "        'dt':         dt,\n",
    "        'dt_save':    dt_save,\n",
    "        'ant_level':  antagonist_level\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ant_levels = [0, .1, .2, .3, .4, .5, .6]\n",
    "for ant_level in ant_levels:\n",
    "    params['ant_level'] = ant_level\n",
    "    r.do(action, args, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycog.figtools import Figure\n",
    "\n",
    "for ant_level in ant_levels:\n",
    "    trialsfile = join(trialspath, name + '_ant_level_' + \n",
    "                      str(ant_level) + '_trials.pkl')\n",
    "    fig = Figure()\n",
    "    plot = fig.add()\n",
    "    plot.xlabel(r'\\% coherence towards choice 1')\n",
    "    plot.ylabel(r'Percent choice 1')\n",
    "    plot.text_upper_left('Antagonist Level {}'.format(str(ant_level)))\n",
    "    r.psychometric_function(trialsfile, plot=plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pycog.rnn import RNN\n",
    "for ant_level in ant_levels:\n",
    "    rnn = RNN(params['savefile'], {'dt': params['dt']}, verbose=False)\n",
    "    rnn.Wrec[np.where(rnn.Wrec<0)] *= (1-ant_level)\n",
    "    rnn.plot_structure()\n",
    "    print(ant_level)\n",
    "    sys.stdout.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [RNN]",
   "language": "python",
   "name": "Python [RNN]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
